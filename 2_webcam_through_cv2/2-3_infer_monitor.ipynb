{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4afcb0ec2d74b8ce",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 모니터 추론하기\n",
    "\n",
    "지금까지 이미지 및 동영상파일, 내장카메라 및 USB카메라, IP카메라 등 다양한 인풋에 대해 실습해보았습니다.\n",
    "\n",
    "이번 챕터에서는 마지막으로 모니터를 인풋으로 추론을 수행하는 코드를 알아보겠습니다.\n",
    "\n",
    "(참고로 이번 예제에서는 mss 모듈을 추가로 설치합니다. 이를 통해 스크린샷을 빠르게 찍습니다.)\n",
    "\n",
    "기본적으로 주모니터의 인덱스는 0입니다. 보조모니터가 있다면 연결 순서대로 1, 2, 3이 됩니다.\n",
    "\n",
    "아래 코드를 읽어본 후 실행해보시기 바랍니다.\n",
    "\n",
    "이전과 마찬가지로 화면에 보이는 사람의 수를 세어서 화면에 출력하는 작업을 수행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import mss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-03T13:04:20.074203800Z",
     "start_time": "2024-02-03T13:04:20.041556Z"
    }
   },
   "id": "235c1e463e4acec5",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269b5cb678216617",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pip install ultralytics opencv-python mss numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80c65042ff248a28",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-03T13:12:34.836711100Z",
     "start_time": "2024-02-03T13:11:31.664344600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 416x640 3 persons, 1443.7ms\n",
      "Speed: 31.7ms preprocess, 1443.7ms inference, 16.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  3\n",
      "0: 416x640 6 persons, 237.7ms\n",
      "Speed: 6.5ms preprocess, 237.7ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  6\n",
      "0: 416x640 8 persons, 1 giraffe, 1 tv, 269.7ms\n",
      "Speed: 7.0ms preprocess, 269.7ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  8\n",
      "0: 416x640 8 persons, 1 giraffe, 1 tv, 257.2ms\n",
      "Speed: 6.5ms preprocess, 257.2ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  8\n",
      "0: 416x640 8 persons, 1 giraffe, 1 tv, 261.9ms\n",
      "Speed: 7.0ms preprocess, 261.9ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  8\n",
      "0: 416x640 8 persons, 1 giraffe, 2 tvs, 254.1ms\n",
      "Speed: 7.5ms preprocess, 254.1ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  8\n",
      "0: 416x640 10 persons, 1 giraffe, 2 tvs, 289.6ms\n",
      "Speed: 7.5ms preprocess, 289.6ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  10\n",
      "\n",
      "0: 416x640 8 persons, 1 giraffe, 1 tv, 251.3ms\n",
      "Speed: 6.0ms preprocess, 251.3ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  8\n",
      "0: 416x640 7 persons, 1 giraffe, 1 tv, 269.3ms\n",
      "Speed: 7.5ms preprocess, 269.3ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  7\n",
      "\n",
      "0: 416x640 7 persons, 1 giraffe, 1 tv, 270.1ms\n",
      "Speed: 6.0ms preprocess, 270.1ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  7\n",
      "\n",
      "0: 416x640 7 persons, 1 giraffe, 1 tv, 470.8ms\n",
      "Speed: 6.5ms preprocess, 470.8ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  7\n",
      "\n",
      "0: 416x640 6 persons, 2 giraffes, 1 tv, 367.7ms\n",
      "Speed: 6.5ms preprocess, 367.7ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  6\n",
      "0: 416x640 6 persons, 2 giraffes, 1 tv, 265.7ms\n",
      "Speed: 6.0ms preprocess, 265.7ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  6\n",
      "0: 416x640 6 persons, 1 giraffe, 1 tv, 282.6ms\n",
      "Speed: 7.0ms preprocess, 282.6ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  6\n",
      "0: 416x640 6 persons, 1 giraffe, 1 tv, 268.5ms\n",
      "Speed: 7.6ms preprocess, 268.5ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  6\n",
      "\n",
      "0: 416x640 7 persons, 1 giraffe, 2 tvs, 245.8ms\n",
      "Speed: 7.0ms preprocess, 245.8ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  7\n",
      "0: 416x640 6 persons, 1 giraffe, 1 tv, 254.8ms\n",
      "Speed: 5.0ms preprocess, 254.8ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  6\n",
      "0: 416x640 5 persons, 1 giraffe, 1 tv, 504.2ms\n",
      "Speed: 14.1ms preprocess, 504.2ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  5\n",
      "0: 416x640 5 persons, 1 giraffe, 510.5ms\n",
      "Speed: 11.5ms preprocess, 510.5ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  5\n",
      "0: 416x640 4 persons, 2 giraffes, 2 tvs, 604.6ms\n",
      "Speed: 6.5ms preprocess, 604.6ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  4\n",
      "0: 416x640 4 persons, 2 giraffes, 570.6ms\n",
      "Speed: 6.5ms preprocess, 570.6ms inference, 8.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  4\n",
      "0: 416x640 4 persons, 2 giraffes, 770.3ms\n",
      "Speed: 6.5ms preprocess, 770.3ms inference, 8.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  4\n",
      "0: 416x640 4 persons, 1 giraffe, 459.1ms\n",
      "Speed: 6.5ms preprocess, 459.1ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  4\n",
      "\n",
      "0: 416x640 4 persons, 2 giraffes, 498.6ms\n",
      "Speed: 24.6ms preprocess, 498.6ms inference, 15.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  4\n",
      "\n",
      "0: 416x640 4 persons, 2 giraffes, 416.5ms\n",
      "Speed: 16.6ms preprocess, 416.5ms inference, 12.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  4\n",
      "0: 416x640 4 persons, 3 giraffes, 1 tv, 1073.3ms\n",
      "Speed: 6.5ms preprocess, 1073.3ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  4\n",
      "0: 416x640 4 persons, 1 giraffe, 1117.8ms\n",
      "Speed: 7.5ms preprocess, 1117.8ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  4\n",
      "0: 416x640 4 persons, 2 tvs, 451.8ms\n",
      "Speed: 6.5ms preprocess, 451.8ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  4\n",
      "0: 416x640 4 persons, 1 giraffe, 1 tv, 429.0ms\n",
      "Speed: 7.5ms preprocess, 429.0ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  4\n",
      "0: 416x640 4 persons, 1 giraffe, 611.9ms\n",
      "Speed: 6.6ms preprocess, 611.9ms inference, 16.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  4\n",
      "\n",
      "0: 416x640 3 persons, 1 tv, 522.0ms\n",
      "Speed: 7.5ms preprocess, 522.0ms inference, 7.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  3\n",
      "0: 416x640 3 persons, 439.0ms\n",
      "Speed: 5.5ms preprocess, 439.0ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  3\n",
      "0: 416x640 3 persons, 1 giraffe, 418.9ms\n",
      "Speed: 9.5ms preprocess, 418.9ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  3\n",
      "0: 416x640 3 persons, 1 giraffe, 670.2ms\n",
      "Speed: 7.6ms preprocess, 670.2ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  3\n",
      "0: 416x640 3 persons, 1 giraffe, 837.0ms\n",
      "Speed: 6.5ms preprocess, 837.0ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  3\n",
      "0: 416x640 3 persons, 508.4ms\n",
      "Speed: 8.5ms preprocess, 508.4ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  3\n",
      "0: 416x640 3 persons, 1 giraffe, 1 tv, 655.8ms\n",
      "Speed: 7.0ms preprocess, 655.8ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  3\n",
      "0: 416x640 3 persons, 1 giraffe, 1 tv, 388.1ms\n",
      "Speed: 14.5ms preprocess, 388.1ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  3\n",
      "0: 416x640 3 persons, 1 giraffe, 549.7ms\n",
      "Speed: 7.5ms preprocess, 549.7ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  3\n",
      "0: 416x640 3 persons, 1 giraffe, 516.7ms\n",
      "Speed: 18.1ms preprocess, 516.7ms inference, 15.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  3\n",
      "0: 416x640 3 persons, 1 giraffe, 428.2ms\n",
      "Speed: 6.0ms preprocess, 428.2ms inference, 3.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  3\n",
      "0: 416x640 3 persons, 1 giraffe, 321.8ms\n",
      "Speed: 25.1ms preprocess, 321.8ms inference, 8.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  3\n",
      "\n",
      "0: 416x640 3 persons, 1 giraffe, 470.7ms\n",
      "Speed: 8.5ms preprocess, 470.7ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  3\n",
      "0: 416x640 3 persons, 1 giraffe, 1 tv, 414.4ms\n",
      "Speed: 11.5ms preprocess, 414.4ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  3\n",
      "0: 416x640 3 persons, 1015.6ms\n",
      "Speed: 6.5ms preprocess, 1015.6ms inference, 7.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  3\n",
      "0: 416x640 4 persons, 673.7ms\n",
      "Speed: 5.5ms preprocess, 673.7ms inference, 9.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "total person no :  4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import mss  # 현존 최고의 스크린샷 모듈\n",
    "\n",
    "\n",
    "def on_exists(fname: str) -> None:\n",
    "    if os.path.isfile(fname):\n",
    "        os.remove(fname)\n",
    "\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "classNames = model.names\n",
    "\n",
    "while True:\n",
    "    with mss.mss() as sct:\n",
    "        img = cv2.imread(sct.shot(output=\"monitor.png\",\n",
    "            mon=0,  # 보조(2번)모니터 찍기. mon 대신 bounding_box 사용 가능\n",
    "            callback=on_exists))  # 기존에 파일이 있으면 지우고 나서 저장\n",
    "        results = model(img)\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            total_person_no = 0\n",
    "            for box in boxes:\n",
    "                if int(box.cls) == 0:  # 사람이면\n",
    "                    # 박스 추출\n",
    "                    x1, y1, x2, y2 = box.xyxy[0]\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)  # convert to int values\n",
    "\n",
    "                    # 네모 그리기\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "\n",
    "                    # 신뢰도 추출\n",
    "                    confidence = box.conf[0]\n",
    "\n",
    "                    # 클래스명 추출\n",
    "                    cls = int(box.cls[0])\n",
    "\n",
    "                    if cls == 0:  # 사람이면\n",
    "                        total_person_no += 1\n",
    "\n",
    "                    # 주석 삽입용 정보\n",
    "                    org = [x1, y1]\n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    fontScale = 1\n",
    "                    color = (255, 0, 0)\n",
    "                    thickness = 1\n",
    "\n",
    "                    cv2.putText(\n",
    "                        img, classNames[cls], org, font, \n",
    "                        fontScale, color, thickness)\n",
    "            print(\"total person no : \", total_person_no)\n",
    "\n",
    "            cv2.imshow('screen', img)\n",
    "\n",
    "    if (cv2.waitKey(1) & 0xFF) == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8189085ff38140f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "촬영영역 안에 cv 창이 떠 있으면 화면이 복잡해지더라도\n",
    "\n",
    "q를 누르면 종료되니 이 점 기억해 주시기 바랍니다.\n",
    "\n",
    "아래 코드는 동일한 작업을 수행하되 모니터의 특정 영역에 대해서만 추론을 수행합니다.\n",
    "\n",
    "영역은 top, left, width, height 등 네 개의 키로 정의하며,\n",
    "\n",
    "아래 코드는 사분할 중 우측 하단 영역에 대해서만 추론을 수행합니다. (FHD1920x1080 기준)\n",
    "\n",
    "(20번 라인부터는 100% 동일합니다.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec155b743e891a2c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import mss  # 현존 최고의 스크린샷 모듈\n",
    "import numpy as np\n",
    "\n",
    "bounding_box = {'top': 540, 'left': 960, 'width': 960, 'height': 540}\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "classNames = model.names\n",
    "\n",
    "\n",
    "while True:\n",
    "    with mss.mss() as sct:\n",
    "        img = np.array(sct.grab(bounding_box))[:, :, :3]  # rgba to rgb\n",
    "        \n",
    "        if not img.flags['C_CONTIGUOUS']:  # 연속메모리배열 여부인지 확인 및 변환\n",
    "            img = np.ascontiguousarray(img)\n",
    "        results = model(img)\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            total_person_no = 0\n",
    "            for box in boxes:\n",
    "                if int(box.cls) == 0:  # 사람이면\n",
    "                    # 박스 추출\n",
    "                    x1, y1, x2, y2 = box.xyxy[0]\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)  # convert to int values\n",
    "\n",
    "                    # 네모 그리기\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "\n",
    "                    # 신뢰도 추출\n",
    "                    confidence = box.conf[0]\n",
    "\n",
    "                    # 클래스명 추출\n",
    "                    cls = int(box.cls[0])\n",
    "\n",
    "                    if cls == 0:  # 사람이면\n",
    "                        total_person_no += 1\n",
    "\n",
    "                    # 주석 삽입용 정보\n",
    "                    org = [x1, y1]\n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    fontScale = 1\n",
    "                    color = (255, 0, 0)\n",
    "                    thickness = 1\n",
    "\n",
    "                    cv2.putText(img, classNames[cls], org, font, fontScale, color, thickness)\n",
    "            print(\"total person no : \", total_person_no)\n",
    "\n",
    "            cv2.imshow('screen', img)\n",
    "\n",
    "    if (cv2.waitKey(1) & 0xFF) == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5513df9aff550c94",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "여기까지 모니터 영역을 입력으로 추론을 수행하는 작업을 해보았습니다.\n",
    "\n",
    "캡쳐나 다운로드가 불가능하지만 웹브라우저에서 조회는 가능한 경우에\n",
    "\n",
    "특히 유용한 추론방법이므로, 기억해 두셨다가 활용해 주시기 바랍니다.\n",
    "\n",
    "![](https://i.ibb.co/xHk8WfL/2024-02-01-16-47-59-59.gif)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
