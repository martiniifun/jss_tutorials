{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Roboflow 활용하기(이어서)\n",
    "\n",
    "이번 챕터에서는 roboflow 서비스를 이용한\n",
    "\n",
    "커스텀 모델 구축 후, 이 모델을 로컬에서 사용하는\n",
    "\n",
    "다양한 방법에 대해 보여드리겠습니다.\n",
    "\n",
    "우선 roboflow에서 제공하는 두 가지 모듈인\n",
    "\n",
    "roboflow와 inference를 가상환경에 설치합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22fdea15fd106a5c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%pip install inference roboflow supervision"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e8340990cc43c5e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "만약 CUDA지원 가능한 NVIDIA GPU가 설치된 PC라면\n",
    "\n",
    "inference 대신 inference-gpu를 설치하셔야 GPU 활용 가능합니다.\n",
    "\n",
    "## 중요 : 환경변수 추가\n",
    "\n",
    "그리고 roboflow에서 제공받은 api-key를 환경변수에 추가하셔야 합니다.\n",
    "\n",
    "환경변수 이름은 ROBOFLOW_API_KEY입니다.\n",
    "\n",
    "내 코드에 환경변수를 그대로 적어놓으면 노출의 위험성이 있습니다.\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6312ed30b0afd9"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-04T10:13:38.438852300Z",
     "start_time": "2024-02-04T10:13:35.206702900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\PycharmProjects\\jss_tutorials\\.venv\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:65: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/cache\\penguin-detection-qyh4k/1\n"
     ]
    }
   ],
   "source": [
    "import inference\n",
    "\n",
    "# 아래 명령을 실행하면 로컬에 모델이 onnx 타입으로 저장됨.\n",
    "inference.models.yolov8.yolov8_object_detection\n",
    "model = inference.get_roboflow_model(\"penguin-detection-qyh4k/1\")\n",
    "\n",
    "# 저장경로는 model.cache_dir로 확인 가능\n",
    "print(model.cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=404.5 y=266.0 width=133.0 height=92.0 confidence=0.8281735181808472 class_name='penguin' class_confidence=None class_id=0 tracker_id=None\n"
     ]
    }
   ],
   "source": [
    "# cache 안에 다운받은 onnx 파일이 있으면\n",
    "# 다시 다운로드하지 않고 해당 파일을 계속 사용합니다.\n",
    "# 기본적인 추론 방법은 아래와 같습니다.\n",
    "\n",
    "orig_img = \"test/p_on_water.jpg\"\n",
    "results = model.infer(image=orig_img)\n",
    "pred = results[0].predictions[0]\n",
    "\n",
    "# 추론결과의 데이터는 아래와 같습니다.\n",
    "# ultralytics와는 달리,\n",
    "# 원본 이미지(orig_img) 배열이 포함되어 있지 않습니다. \n",
    "print(pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T08:38:23.733991400Z",
     "start_time": "2024-02-04T08:38:23.660992800Z"
    }
   },
   "id": "a90d3af42f68895b",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "추론결과의 클래스이름과 신뢰도, xywh좌표가 나와 있습니다.\n",
    "\n",
    "이를 통해 ultralytics로 추출할 때와 유사한 방식으로\n",
    "\n",
    "추론 후의 이미지를 직접 만들어낼 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca51480e015ac1c1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2  # ImportError 발생시 pip install opencv-python 실행\n",
    "\n",
    "def pred_to_xyxy(pred):\n",
    "    \"roboflow의 xywh를 xyxy로 변환하는 함수\"\n",
    "    x1, y1 = pred.x-pred.width/2, pred.y-pred.height/2\n",
    "    x2, y2 = pred.x+pred.width/2, pred.y+pred.height/2\n",
    "    return int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "im0 = cv2.imread(orig_img)  # 이미지를 배열로 불러옴\n",
    "x1, y1, x2, y2 = pred_to_xyxy(pred)\n",
    "\n",
    "# 직접 웹캠이미지에 네모 그리기\n",
    "cv2.rectangle(img=im0,  # 파일명이 아니라 배열을 넣어야 함\n",
    "              pt1=(x1, y1),\n",
    "              pt2=(x2, y2),\n",
    "              color=(255, 0, 255),\n",
    "              thickness=3)\n",
    "\n",
    "org = [x1, y1]  # 주석 작성할 좌표\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 1\n",
    "color = (255, 0, 0)\n",
    "thickness = 2\n",
    "cv2.putText(im0, pred.class_name + f\" {pred.confidence:.02f}\", org, font, fontScale, color, thickness)\n",
    "\n",
    "cv2.imwrite(filename=f\"./result.jpg\", img=im0)\n",
    "cv2.imshow('result', mat=im0)  # opencv 창에 이미지 갱신\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T08:38:31.512170Z",
     "start_time": "2024-02-04T08:38:26.419656900Z"
    }
   },
   "id": "2f898f83ce1dcead",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "23f96ceb38b4424c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# 커스텀 pt인 경우에는 task를 지정해주어야 작동합니다.\n",
    "model = YOLO('./model/weights.onnx', task=\"detect\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T09:41:24.682466300Z",
     "start_time": "2024-02-04T09:41:24.621689900Z"
    }
   },
   "id": "62a967f8325812a4",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 C:\\Users\\Administrator\\PycharmProjects\\jss_tutorials\\6_custom_dataset\\test\\p_on_water.jpg: 640x640 1 penguin, 104.7ms\n",
      "Speed: 4.6ms preprocess, 104.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001B[1mC:\\Users\\Administrator\\PycharmProjects\\jss_tutorials\\runs\\detect\\predict3\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "[ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'penguin'}\n obb: None\n orig_img: array([[[134, 137, 142],\n         [ 82,  85,  90],\n         [ 74,  76,  84],\n         ...,\n         [ 85,  84, 104],\n         [ 78,  77,  97],\n         [ 91,  95, 114]],\n \n        [[104, 107, 112],\n         [ 69,  72,  77],\n         [ 59,  61,  69],\n         ...,\n         [107, 106, 126],\n         [108, 107, 127],\n         [ 96, 100, 119]],\n \n        [[ 52,  55,  60],\n         [ 52,  55,  60],\n         [ 53,  55,  63],\n         ...,\n         [128, 127, 147],\n         [113, 112, 132],\n         [ 94,  95, 115]],\n \n        ...,\n \n        [[ 77,  87, 111],\n         [103, 113, 137],\n         [105, 115, 139],\n         ...,\n         [ 96, 105, 125],\n         [ 99, 108, 128],\n         [ 82,  91, 111]],\n \n        [[ 99, 109, 133],\n         [ 93, 103, 127],\n         [ 93, 103, 127],\n         ...,\n         [ 95, 104, 124],\n         [ 98, 107, 127],\n         [ 85,  94, 114]],\n \n        [[100, 110, 134],\n         [ 94, 104, 128],\n         [ 98, 108, 132],\n         ...,\n         [ 94, 103, 123],\n         [ 96, 105, 125],\n         [105, 114, 134]]], dtype=uint8)\n orig_shape: (563, 750)\n path: 'C:\\\\Users\\\\Administrator\\\\PycharmProjects\\\\jss_tutorials\\\\6_custom_dataset\\\\test\\\\p_on_water.jpg'\n probs: None\n save_dir: 'C:\\\\Users\\\\Administrator\\\\PycharmProjects\\\\jss_tutorials\\\\runs\\\\detect\\\\predict3'\n speed: {'preprocess': 4.63414192199707, 'inference': 104.73942756652832, 'postprocess': 1.0478496551513672}]"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"test/p_on_water.jpg\", save=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T09:42:04.121507200Z",
     "start_time": "2024-02-04T09:42:03.971017100Z"
    }
   },
   "id": "371d6cc02af83a3f",
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 편하긴 한데, 더 저렴한 방법이 없나?\n",
    "\n",
    "지금까지, roboflow에서 학습을 완료하고\n",
    "\n",
    "다운받은 onnx 모델을 사용해서 추론해보았습니다.\n",
    "\n",
    "하지만, 위의 방법은 꽤 비용이 든다고 말씀드렸습니다.\n",
    "\n",
    "> (249$/mon 을 기억하시기 바랍니다.)\n",
    "\n",
    "위와 같이 roboflow에서 제공하는 \n",
    "\n",
    "(비싸지만) 편리한 기능들을 사용하지 않고\n",
    "\n",
    "roboflow에서 레이블링만 완료하고\n",
    "\n",
    "데이터셋을 로컬 또는 코랩으로 다운받아 \n",
    "\n",
    "직접 학습하여 pt 파일을 만드는 방법입니다.\n",
    "\n",
    "(코랩도 돈이 듭니다.)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d665090dfe3efa6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.1.6, to fix: `pip install ultralytics==8.0.196`\n",
      "Exporting format yolov8 in progress : 85.0%\n",
      "Version export complete for yolov8 format\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in penguin-detection-1 to yolov8:: 100%|██████████| 1950/1950 [00:01<00:00, 1474.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to penguin-detection-1 in yolov8:: 100%|██████████| 108/108 [00:00<00:00, 2454.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "rf = Roboflow(\"un7kANfGUhngOf2sYCk3\")\n",
    "# proj = rf.workspace(\"Martin Shin\")\n",
    "# proj = rf.workspace(\"penguin-detection-qyh4k/1\")\n",
    "prj = rf.workspace(\"martin-shin-ipe9b\").project('penguin-detection-qyh4k')\n",
    "dataset = prj.version(1).download('yolov8')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T08:57:09.324888Z",
     "start_time": "2024-02-04T08:56:57.514282Z"
    }
   },
   "id": "b642d74e61d5de98",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\Administrator\\\\PycharmProjects\\\\jss_tutorials\\\\6_custom_dataset\\\\penguin-detection-1'"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset.location을 열어보면 \n",
    "# 데이터셋 다운로드 경로가 나옵니다.\n",
    "\n",
    "dataset.location"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1252834d9dece617",
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "다운로드한 데이터셋의 data.yaml을 열어보면 \n",
    "\n",
    "아래와 같습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4345aa9b46d00dcf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- penguin\n",
    "nc: 1\n",
    "roboflow:\n",
    "  license: CC BY 4.0\n",
    "  project: penguin-detection-qyh4k\n",
    "  url: https://universe.roboflow.com/martin-shin-ipe9b/penguin-detection-qyh4k/dataset/1\n",
    "  version: 1\n",
    "  workspace: martin-shin-ipe9b\n",
    "test: test/images\n",
    "train: train/images\n",
    "val: valid/images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfabcf5d3a9a7359"
  },
  {
   "cell_type": "markdown",
   "source": [
    "가끔 데이터셋의 경로가 잘못 기재되는 경우가 있는데,\n",
    "\n",
    "test, train, val을 적절히 설정해주면 됩니다.\n",
    "\n",
    "예를 들어 제 경우에는 기존의 아래 세 라인을"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc973dbbb70d0035"
  },
  {
   "cell_type": "markdown",
   "source": [
    "test: ../test/images\n",
    "train: penguin-detection-1/train/images\n",
    "val: penguin-detection-1/valid/images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "319be6a2b6f33856"
  },
  {
   "cell_type": "markdown",
   "source": [
    "아래와 같이 수정하였습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef1ec40504a89e01"
  },
  {
   "cell_type": "markdown",
   "source": [
    "test: test/images\n",
    "train: train/images\n",
    "val: val/images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1064133ff3c16eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "아래부터는 로컬에서 학습하는 코드입니다.\n",
    "\n",
    "(시간관계상 10에포크만 수행해보았습니다.)\n",
    "\n",
    "제 랩탑 기준으로 약 8분 정도 걸리네요.\n",
    "\n",
    "일반적으로 100에포크 전후로 돌리기는 합니다.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc8081ad827e9ceb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.9 available �윑� Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.6 �윓� Python-3.10.11 torch-2.1.2+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0mtask=detect, mode=train, model=yolov8s.pt, data=C:\\Users\\Administrator\\PycharmProjects\\jss_tutorials\\6_custom_dataset\\penguin-detection-1/data.yaml, epochs=10, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\Administrator\\PycharmProjects\\jss_tutorials\\runs\\detect\\train2\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: C:\\Users\\Administrator\\PycharmProjects\\jss_tutorials\\6_custom_dataset\\penguin-detection-1\\train\\labels.cache\n",
      "\u001B[34m\u001B[1mval: \u001B[0mNew cache created: C:\\Users\\Administrator\\PycharmProjects\\jss_tutorials\\6_custom_dataset\\penguin-detection-1\\valid\\labels.cache\n",
      "Plotting labels to C:\\Users\\Administrator\\PycharmProjects\\jss_tutorials\\runs\\detect\\train2\\labels.jpg... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001B[1mC:\\Users\\Administrator\\PycharmProjects\\jss_tutorials\\runs\\detect\\train2\u001B[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all          4          6      0.327        0.5      0.434      0.349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all          4          6      0.972      0.833      0.931      0.794\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all          4          6      0.792          1      0.876      0.654\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all          4          6      0.818          1      0.924      0.649\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all          4          6          1      0.958      0.995      0.698\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all          4          6      0.996          1      0.995      0.767\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all          4          6          1       0.99      0.995      0.774\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all          4          6          1      0.998      0.995      0.805\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all          4          6          1      0.996      0.995      0.827\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all          4          6      0.976      0.833      0.972      0.789\n",
      "\n",
      "10 epochs completed in 0.124 hours.\n",
      "Optimizer stripped from C:\\Users\\Administrator\\PycharmProjects\\jss_tutorials\\runs\\detect\\train2\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from C:\\Users\\Administrator\\PycharmProjects\\jss_tutorials\\runs\\detect\\train2\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating C:\\Users\\Administrator\\PycharmProjects\\jss_tutorials\\runs\\detect\\train2\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.6 �윓� Python-3.10.11 torch-2.1.2+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n",
      "                   all          4          6          1      0.995      0.995      0.827\n",
      "Speed: 2.1ms preprocess, 367.1ms inference, 0.0ms loss, 11.8ms postprocess per image\n",
      "Results saved to \u001B[1mC:\\Users\\Administrator\\PycharmProjects\\jss_tutorials\\runs\\detect\\train2\u001B[0m\n",
      "�윊� Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\Administrator\\PycharmProjects\\jss_tutorials\\6_custom_dataset\\penguin-detection-1\\train\\labels...:   0%|          | 0/42 [00:00<?, ?it/s]\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\Administrator\\PycharmProjects\\jss_tutorials\\6_custom_dataset\\penguin-detection-1\\train\\labels... 42 images, 9 backgrounds, 0 corrupt: 100%|##########| 42/42 [00:00<00:00, 1678.38it/s]\n",
      "\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\Administrator\\PycharmProjects\\jss_tutorials\\6_custom_dataset\\penguin-detection-1\\valid\\labels...:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\Administrator\\PycharmProjects\\jss_tutorials\\6_custom_dataset\\penguin-detection-1\\valid\\labels... 4 images, 1 backgrounds, 0 corrupt: 100%|##########| 4/4 [00:00<00:00, 1283.35it/s]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "       1/10         0G      1.363      3.739      1.398         43        640:   0%|          | 0/3 [00:10<?, ?it/s]\n",
      "       1/10         0G      1.363      3.739      1.398         43        640:  33%|###3      | 1/3 [00:10<00:21, 10.95s/it]\n",
      "       1/10         0G      1.533      5.385      1.492         19        640:  33%|###3      | 1/3 [00:22<00:21, 10.95s/it]\n",
      "       1/10         0G      1.533      5.385      1.492         19        640:  67%|######6   | 2/3 [00:22<00:11, 11.14s/it]\n",
      "       1/10         0G      1.674      5.047      1.671         18        640:  67%|######6   | 2/3 [00:29<00:11, 11.14s/it]\n",
      "       1/10         0G      1.674      5.047      1.671         18        640: 100%|##########| 3/3 [00:29<00:00,  9.51s/it]\n",
      "       1/10         0G      1.674      5.047      1.671         18        640: 100%|##########| 3/3 [00:29<00:00,  9.93s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:01<00:00,  1.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:01<00:00,  1.25s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "       2/10         0G      1.181      4.136      1.211         19        640:   0%|          | 0/3 [00:11<?, ?it/s]\n",
      "       2/10         0G      1.181      4.136      1.211         19        640:  33%|###3      | 1/3 [00:11<00:23, 11.92s/it]\n",
      "       2/10         0G       1.16      3.459      1.272         31        640:  33%|###3      | 1/3 [00:23<00:23, 11.92s/it]\n",
      "       2/10         0G       1.16      3.459      1.272         31        640:  67%|######6   | 2/3 [00:23<00:11, 11.97s/it]\n",
      "       2/10         0G       1.23       2.94      1.287         26        640:  67%|######6   | 2/3 [00:31<00:11, 11.97s/it]\n",
      "       2/10         0G       1.23       2.94      1.287         26        640: 100%|##########| 3/3 [00:31<00:00,  9.97s/it]\n",
      "       2/10         0G       1.23       2.94      1.287         26        640: 100%|##########| 3/3 [00:31<00:00, 10.50s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:01<00:00,  1.87s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:01<00:00,  1.87s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "       3/10         0G      1.282      2.549      1.327         27        640:   0%|          | 0/3 [00:17<?, ?it/s]\n",
      "       3/10         0G      1.282      2.549      1.327         27        640:  33%|###3      | 1/3 [00:17<00:35, 17.50s/it]\n",
      "       3/10         0G      1.231      2.331      1.276         33        640:  33%|###3      | 1/3 [00:35<00:35, 17.50s/it]\n",
      "       3/10         0G      1.231      2.331      1.276         33        640:  67%|######6   | 2/3 [00:35<00:17, 17.52s/it]\n",
      "       3/10         0G      1.146      2.149      1.231         18        640:  67%|######6   | 2/3 [00:44<00:17, 17.52s/it]\n",
      "       3/10         0G      1.146      2.149      1.231         18        640: 100%|##########| 3/3 [00:44<00:00, 13.62s/it]\n",
      "       3/10         0G      1.146      2.149      1.231         18        640: 100%|##########| 3/3 [00:44<00:00, 14.67s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:01<00:00,  1.83s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:01<00:00,  1.83s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "       4/10         0G      1.132      1.875      1.161         38        640:   0%|          | 0/3 [00:14<?, ?it/s]\n",
      "       4/10         0G      1.132      1.875      1.161         38        640:  33%|###3      | 1/3 [00:14<00:28, 14.43s/it]\n",
      "       4/10         0G      1.037       1.87       1.14         30        640:  33%|###3      | 1/3 [00:29<00:28, 14.43s/it]\n",
      "       4/10         0G      1.037       1.87       1.14         30        640:  67%|######6   | 2/3 [00:29<00:14, 14.95s/it]\n",
      "       4/10         0G      1.042       2.02      1.116         13        640:  67%|######6   | 2/3 [00:38<00:14, 14.95s/it]\n",
      "       4/10         0G      1.042       2.02      1.116         13        640: 100%|##########| 3/3 [00:38<00:00, 12.21s/it]\n",
      "       4/10         0G      1.042       2.02      1.116         13        640: 100%|##########| 3/3 [00:38<00:00, 12.90s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:01<00:00,  1.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:01<00:00,  1.74s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "       5/10         0G        1.2      2.176      1.123         23        640:   0%|          | 0/3 [00:14<?, ?it/s]\n",
      "       5/10         0G        1.2      2.176      1.123         23        640:  33%|###3      | 1/3 [00:14<00:29, 14.92s/it]\n",
      "       5/10         0G      1.127      2.165      1.101         32        640:  33%|###3      | 1/3 [00:29<00:29, 14.92s/it]\n",
      "       5/10         0G      1.127      2.165      1.101         32        640:  67%|######6   | 2/3 [00:29<00:14, 14.97s/it]\n",
      "       5/10         0G       1.12        1.9      1.096         24        640:  67%|######6   | 2/3 [00:39<00:14, 14.97s/it]\n",
      "       5/10         0G       1.12        1.9      1.096         24        640: 100%|##########| 3/3 [00:39<00:00, 12.31s/it]\n",
      "       5/10         0G       1.12        1.9      1.096         24        640: 100%|##########| 3/3 [00:39<00:00, 13.02s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:01<00:00,  1.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:01<00:00,  1.45s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "       6/10         0G      1.073      1.597     0.9841         23        640:   0%|          | 0/3 [00:15<?, ?it/s]\n",
      "       6/10         0G      1.073      1.597     0.9841         23        640:  33%|###3      | 1/3 [00:15<00:30, 15.20s/it]\n",
      "       6/10         0G      1.068      1.522      1.067         34        640:  33%|###3      | 1/3 [00:30<00:30, 15.20s/it]\n",
      "       6/10         0G      1.068      1.522      1.067         34        640:  67%|######6   | 2/3 [00:30<00:15, 15.08s/it]\n",
      "       6/10         0G      1.009      1.414      1.028         21        640:  67%|######6   | 2/3 [00:39<00:15, 15.08s/it]\n",
      "       6/10         0G      1.009      1.414      1.028         21        640: 100%|##########| 3/3 [00:39<00:00, 12.39s/it]\n",
      "       6/10         0G      1.009      1.414      1.028         21        640: 100%|##########| 3/3 [00:39<00:00, 13.13s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:01<00:00,  1.63s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:01<00:00,  1.63s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "       7/10         0G      1.105      1.516      1.188         23        640:   0%|          | 0/3 [00:15<?, ?it/s]\n",
      "       7/10         0G      1.105      1.516      1.188         23        640:  33%|###3      | 1/3 [00:15<00:30, 15.34s/it]\n",
      "       7/10         0G      1.126      1.335      1.205         41        640:  33%|###3      | 1/3 [00:34<00:30, 15.34s/it]\n",
      "       7/10         0G      1.126      1.335      1.205         41        640:  67%|######6   | 2/3 [00:34<00:17, 17.81s/it]\n",
      "       7/10         0G      1.097      1.355      1.148         14        640:  67%|######6   | 2/3 [00:49<00:17, 17.81s/it]\n",
      "       7/10         0G      1.097      1.355      1.148         14        640: 100%|##########| 3/3 [00:49<00:00, 16.33s/it]\n",
      "       7/10         0G      1.097      1.355      1.148         14        640: 100%|##########| 3/3 [00:49<00:00, 16.48s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:02<00:00,  2.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:02<00:00,  2.09s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "       8/10         0G      1.003       1.15      1.059         32        640:   0%|          | 0/3 [00:23<?, ?it/s]\n",
      "       8/10         0G      1.003       1.15      1.059         32        640:  33%|###3      | 1/3 [00:23<00:47, 23.85s/it]\n",
      "       8/10         0G       1.01       1.18      1.109         29        640:  33%|###3      | 1/3 [00:48<00:47, 23.85s/it]\n",
      "       8/10         0G       1.01       1.18      1.109         29        640:  67%|######6   | 2/3 [00:48<00:24, 24.17s/it]\n",
      "       8/10         0G     0.9547      1.204      1.062         15        640:  67%|######6   | 2/3 [00:59<00:24, 24.17s/it]\n",
      "       8/10         0G     0.9547      1.204      1.062         15        640: 100%|##########| 3/3 [00:59<00:00, 18.35s/it]\n",
      "       8/10         0G     0.9547      1.204      1.062         15        640: 100%|##########| 3/3 [00:59<00:00, 19.89s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:02<00:00,  2.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:02<00:00,  2.09s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "       9/10         0G     0.9641      1.072      1.049         34        640:   0%|          | 0/3 [00:17<?, ?it/s]\n",
      "       9/10         0G     0.9641      1.072      1.049         34        640:  33%|###3      | 1/3 [00:17<00:35, 17.93s/it]\n",
      "       9/10         0G      1.004      1.121       1.08         28        640:  33%|###3      | 1/3 [00:33<00:35, 17.93s/it]\n",
      "       9/10         0G      1.004      1.121       1.08         28        640:  67%|######6   | 2/3 [00:33<00:16, 16.79s/it]\n",
      "       9/10         0G     0.9866      1.128      1.054         18        640:  67%|######6   | 2/3 [00:44<00:16, 16.79s/it]\n",
      "       9/10         0G     0.9866      1.128      1.054         18        640: 100%|##########| 3/3 [00:44<00:00, 14.05s/it]\n",
      "       9/10         0G     0.9866      1.128      1.054         18        640: 100%|##########| 3/3 [00:44<00:00, 14.90s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:01<00:00,  1.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:01<00:00,  1.82s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "      10/10         0G     0.9822      1.098      1.048         26        640:   0%|          | 0/3 [00:18<?, ?it/s]\n",
      "      10/10         0G     0.9822      1.098      1.048         26        640:  33%|###3      | 1/3 [00:18<00:36, 18.42s/it]\n",
      "      10/10         0G     0.9358      1.038      1.029         32        640:  33%|###3      | 1/3 [00:37<00:36, 18.42s/it]\n",
      "      10/10         0G     0.9358      1.038      1.029         32        640:  67%|######6   | 2/3 [00:37<00:19, 19.05s/it]\n",
      "      10/10         0G     0.9648      1.089      1.116         19        640:  67%|######6   | 2/3 [00:49<00:19, 19.05s/it]\n",
      "      10/10         0G     0.9648      1.089      1.116         19        640: 100%|##########| 3/3 [00:49<00:00, 15.68s/it]\n",
      "      10/10         0G     0.9648      1.089      1.116         19        640: 100%|##########| 3/3 [00:49<00:00, 16.53s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:02<00:00,  2.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:02<00:00,  2.02s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:01<00:00,  1.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:01<00:00,  1.57s/it]\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=10 imgsz=640"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T09:09:19.027722300Z",
     "start_time": "2024-02-04T09:01:35.235657900Z"
    }
   },
   "id": "9e7a3efbd975081a",
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "학습이 완료되었습니다.\n",
    "\n",
    "메시지의 `Results saved to ~` 에 있는 경로로 찾아가서\n",
    "\n",
    "best.pt 파일을 현재 폴더로 복사한 후에\n",
    "\n",
    "이전과 동일하게 아래 방식으로 코드를 실행하시면 됩니다.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f7ae65e7979b9a1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = YOLO('best.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T09:14:07.287132400Z",
     "start_time": "2024-02-04T09:14:07.225228600Z"
    }
   },
   "id": "175a543d79af6ef3",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 C:\\Users\\Administrator\\PycharmProjects\\jss_tutorials\\6_custom_dataset\\test\\p_on_water.jpg: 480x640 1 penguin, 193.7ms\n",
      "Speed: 3.3ms preprocess, 193.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001B[1mC:\\Users\\Administrator\\PycharmProjects\\jss_tutorials\\runs\\detect\\predict2\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "[ultralytics.engine.results.Results object with attributes:\n \n boxes: ultralytics.engine.results.Boxes object\n keypoints: None\n masks: None\n names: {0: 'penguin'}\n obb: None\n orig_img: array([[[134, 137, 142],\n         [ 82,  85,  90],\n         [ 74,  76,  84],\n         ...,\n         [ 85,  84, 104],\n         [ 78,  77,  97],\n         [ 91,  95, 114]],\n \n        [[104, 107, 112],\n         [ 69,  72,  77],\n         [ 59,  61,  69],\n         ...,\n         [107, 106, 126],\n         [108, 107, 127],\n         [ 96, 100, 119]],\n \n        [[ 52,  55,  60],\n         [ 52,  55,  60],\n         [ 53,  55,  63],\n         ...,\n         [128, 127, 147],\n         [113, 112, 132],\n         [ 94,  95, 115]],\n \n        ...,\n \n        [[ 77,  87, 111],\n         [103, 113, 137],\n         [105, 115, 139],\n         ...,\n         [ 96, 105, 125],\n         [ 99, 108, 128],\n         [ 82,  91, 111]],\n \n        [[ 99, 109, 133],\n         [ 93, 103, 127],\n         [ 93, 103, 127],\n         ...,\n         [ 95, 104, 124],\n         [ 98, 107, 127],\n         [ 85,  94, 114]],\n \n        [[100, 110, 134],\n         [ 94, 104, 128],\n         [ 98, 108, 132],\n         ...,\n         [ 94, 103, 123],\n         [ 96, 105, 125],\n         [105, 114, 134]]], dtype=uint8)\n orig_shape: (563, 750)\n path: 'C:\\\\Users\\\\Administrator\\\\PycharmProjects\\\\jss_tutorials\\\\6_custom_dataset\\\\test\\\\p_on_water.jpg'\n probs: None\n save_dir: 'C:\\\\Users\\\\Administrator\\\\PycharmProjects\\\\jss_tutorials\\\\runs\\\\detect\\\\predict2'\n speed: {'preprocess': 3.278493881225586, 'inference': 193.67432594299316, 'postprocess': 1.129150390625}]"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(orig_img, save=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T09:14:10.632564200Z",
     "start_time": "2024-02-04T09:14:08.643020500Z"
    }
   },
   "id": "fce86aab784c9ae7",
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "source": [
    "아래와 같은 이미지가 만들어졌네요.\n",
    "\n",
    "![](https://i.ibb.co/MNJcnR1/p-on-water.jpg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15488c567f6adbbe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
